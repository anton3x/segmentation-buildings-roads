{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MIT License\n",
    "# Copyright (c) 2017 Vooban Inc.\n",
    "# Coded by: Guillaume Chevalier (original)\n",
    "# Adapted for PyTorch by [Your Name]\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "from torch.cuda.amp import autocast\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "# Global flag to control plotting during processing\n",
    "PLOT_PROGRESS = True\n",
    "\n",
    "# Global cache for precomputed window functions\n",
    "cached_2d_windows = {}\n",
    "\n",
    "def _spline_window(window_size, power=2):\n",
    "    \"\"\"\n",
    "    Create a 1D squared-spline window.\n",
    "    \"\"\"\n",
    "    n = torch.arange(window_size, dtype=torch.float32)\n",
    "    if window_size % 2 == 1:\n",
    "        center = (window_size - 1) / 2\n",
    "        window = 1 - torch.abs(n - center) / (center + 1)\n",
    "    else:\n",
    "        center = (window_size - 1) / 2\n",
    "        window = 1 - torch.abs(n - center) / (window_size / 2)\n",
    "\n",
    "    intersection = window_size // 4\n",
    "    wind_outer = (torch.abs(2 * window) ** power) / 2\n",
    "    wind_outer[intersection:window_size - intersection] = 0\n",
    "    wind_inner = 1 - (torch.abs(2 * (window - 1)) ** power) / 2\n",
    "    wind_inner[:intersection] = 0\n",
    "    wind_inner[window_size - intersection:] = 0\n",
    "    wind = wind_inner + wind_outer\n",
    "    wind = wind / torch.mean(wind)\n",
    "    return wind\n",
    "\n",
    "def _window_2D(window_size, power=2):\n",
    "    \"\"\"\n",
    "    Create a 2D window from the 1D spline window (via outer product) and cache it.\n",
    "    The returned tensor is of shape (1, 1, window_size, window_size) so that it\n",
    "    can broadcast properly over batches and channel dimensions.\n",
    "    \"\"\"\n",
    "    key = f\"{window_size}_{power}\"\n",
    "    if key in cached_2d_windows:\n",
    "        return cached_2d_windows[key]\n",
    "    wind1d = _spline_window(window_size, power)\n",
    "    wind2d = wind1d.unsqueeze(1) * wind1d.unsqueeze(0)  # outer product, shape (window_size, window_size)\n",
    "    wind2d = wind2d.unsqueeze(0).unsqueeze(0)  # shape: (1, 1, window_size, window_size)\n",
    "    if PLOT_PROGRESS:\n",
    "        plt.imshow(wind2d.squeeze().cpu().numpy(), cmap=\"viridis\")\n",
    "        plt.title(\"2D Windowing Function for a Smooth Blending of Overlapping Patches\")\n",
    "        plt.show()\n",
    "    cached_2d_windows[key] = wind2d\n",
    "    return wind2d\n",
    "\n",
    "def _pad_img(img, window_size, subdivisions):\n",
    "    \"\"\"\n",
    "    Pads the input image (tensor of shape (C, H, W)) using reflection.\n",
    "    \"\"\"\n",
    "    aug = int(round(window_size * (1 - 1.0/subdivisions)))\n",
    "    # F.pad uses the pad tuple in the order (left, right, top, bottom)\n",
    "    padded_img = F.pad(img, (aug, aug, aug, aug), mode='reflect')\n",
    "    if PLOT_PROGRESS:\n",
    "        plt.imshow(padded_img.permute(1, 2, 0).cpu().numpy())\n",
    "        plt.title(\"Padded Image for Using Tiled Prediction Patches (reflect)\")\n",
    "        plt.show()\n",
    "    return padded_img\n",
    "\n",
    "def _unpad_img(padded_img, window_size, subdivisions):\n",
    "    \"\"\"\n",
    "    Remove the extra padding added by _pad_img.\n",
    "    \"\"\"\n",
    "    aug = int(round(window_size * (1 - 1.0/subdivisions)))\n",
    "    return padded_img[:, aug:-aug, aug:-aug]\n",
    "\n",
    "def _rotate_mirror_do(im):\n",
    "    \"\"\"\n",
    "    Create the 8 transformations (rotations and horizontal flips) of the image.\n",
    "    Input is assumed to be a tensor of shape (C, H, W).\n",
    "    \"\"\"\n",
    "    transforms = []\n",
    "    transforms.append(im.clone())\n",
    "    transforms.append(torch.rot90(im, k=1, dims=(1, 2)))\n",
    "    transforms.append(torch.rot90(im, k=2, dims=(1, 2)))\n",
    "    transforms.append(torch.rot90(im, k=3, dims=(1, 2)))\n",
    "    im_flipped = torch.flip(im, dims=[2])  # horizontal flip\n",
    "    transforms.append(im_flipped)\n",
    "    transforms.append(torch.rot90(im_flipped, k=1, dims=(1, 2)))\n",
    "    transforms.append(torch.rot90(im_flipped, k=2, dims=(1, 2)))\n",
    "    transforms.append(torch.rot90(im_flipped, k=3, dims=(1, 2)))\n",
    "    return transforms\n",
    "\n",
    "def _rotate_mirror_undo(im_mirrs):\n",
    "    \"\"\"\n",
    "    Invert the 8 transformations and average the results.\n",
    "    \"\"\"\n",
    "    originals = []\n",
    "    originals.append(im_mirrs[0])\n",
    "    originals.append(torch.rot90(im_mirrs[1], k=3, dims=(1, 2)))\n",
    "    originals.append(torch.rot90(im_mirrs[2], k=2, dims=(1, 2)))\n",
    "    originals.append(torch.rot90(im_mirrs[3], k=1, dims=(1, 2)))\n",
    "    originals.append(torch.flip(im_mirrs[4], dims=[2]))\n",
    "    originals.append(torch.flip(torch.rot90(im_mirrs[5], k=3, dims=(1, 2)), dims=[2]))\n",
    "    originals.append(torch.flip(torch.rot90(im_mirrs[6], k=2, dims=(1, 2)), dims=[2]))\n",
    "    originals.append(torch.flip(torch.rot90(im_mirrs[7], k=1, dims=(1, 2)), dims=[2]))\n",
    "    return torch.stack(originals, dim=0).mean(dim=0)\n",
    "\n",
    "def _windowed_subdivs(padded_img, window_size, subdivisions, nb_classes, pred_func):\n",
    "    \"\"\"\n",
    "    Extract overlapping patches from the padded image, run prediction on the batch,\n",
    "    and weight each patch with a 2D window.\n",
    "    \"\"\"\n",
    "    WINDOW_SPLINE_2D = _window_2D(window_size, power=2).to(padded_img.device)\n",
    "    step = window_size // subdivisions\n",
    "    C, H, W = padded_img.shape\n",
    "    patches = []\n",
    "    for i in range(0, H - window_size + 1, step):\n",
    "        row_patches = []\n",
    "        for j in range(0, W - window_size + 1, step):\n",
    "            patch = padded_img[:, i:i+window_size, j:j+window_size]\n",
    "            row_patches.append(patch)\n",
    "        patches.append(row_patches)\n",
    "    num_rows = len(patches)\n",
    "    num_cols = len(patches[0])\n",
    "    patches_tensor = torch.stack([p for row in patches for p in row], dim=0)\n",
    "    # pred_func should accept a tensor of shape (B, C, window_size, window_size)\n",
    "    pred = pred_func(patches_tensor)  # expected output: (B, nb_classes, window_size, window_size)\n",
    "    pred = pred * WINDOW_SPLINE_2D  # apply window weighting\n",
    "    pred = pred.view(num_rows, num_cols, nb_classes, window_size, window_size)\n",
    "    return pred\n",
    "\n",
    "def _recreate_from_subdivs(subdivs, window_size, subdivisions, padded_out_shape):\n",
    "    \"\"\"\n",
    "    Merge the weighted overlapping patches back into a full image.\n",
    "    \"\"\"\n",
    "    step = window_size // subdivisions\n",
    "    nb_classes, H, W = padded_out_shape\n",
    "    y = torch.zeros(padded_out_shape, device=subdivs.device)\n",
    "    num_rows = subdivs.shape[0]\n",
    "    num_cols = subdivs.shape[1]\n",
    "    row_idx = 0\n",
    "    for i in range(0, H - window_size + 1, step):\n",
    "        col_idx = 0\n",
    "        for j in range(0, W - window_size + 1, step):\n",
    "            y[:, i:i+window_size, j:j+window_size] += subdivs[row_idx, col_idx]\n",
    "            col_idx += 1\n",
    "        row_idx += 1\n",
    "    y = y / (subdivisions ** 2)\n",
    "    return y\n",
    "\n",
    "def predict_img_with_smooth_windowing_batched(input_img, window_size, subdivisions, nb_classes, pred_func, batch_size=16):\n",
    "    \"\"\"\n",
    "    Processa a imagem de entrada (tensor com shape (C, H, W)) usando smooth blending,\n",
    "    mas processa os patches em batches menores para evitar estourar a memória.\n",
    "\n",
    "    Args:\n",
    "        input_img: tensor da imagem completa (C, H, W).\n",
    "        window_size: tamanho do patch original (ex.: 256).\n",
    "        subdivisions: fator de subdivisão (determina a sobreposição).\n",
    "        nb_classes: número de canais de saída do modelo.\n",
    "        pred_func: função que realiza a inferência em um batch de patches.\n",
    "                   Espera input de shape (B, C, window_size, window_size) e retorna\n",
    "                   (B, nb_classes, window_size, window_size).\n",
    "        batch_size: quantidade de patches processados de cada vez.\n",
    "\n",
    "    Retorna:\n",
    "        Tensor com a predição final (nb_classes, H, W).\n",
    "    \"\"\"\n",
    "    # Aplica padding à imagem\n",
    "    pad = _pad_img(input_img, window_size, subdivisions)\n",
    "    # Gera as 8 rotações/mirrors\n",
    "    rotations = _rotate_mirror_do(pad)\n",
    "    results = []\n",
    "\n",
    "    # Para cada rotação, extraímos os patches e os processamos em batches\n",
    "    for rot_img in rotations:\n",
    "        C, H, W = rot_img.shape\n",
    "        step = window_size // subdivisions\n",
    "        patches = []\n",
    "        coords = []\n",
    "        # Extrai os patches com sobreposição\n",
    "        for i in range(0, H - window_size + 1, step):\n",
    "            for j in range(0, W - window_size + 1, step):\n",
    "                patch = rot_img[:, i:i+window_size, j:j+window_size]\n",
    "                patches.append(patch)\n",
    "                coords.append((i, j))\n",
    "\n",
    "        # Processa os patches em batches menores\n",
    "        preds = []\n",
    "        for i in range(0, len(patches), batch_size):\n",
    "            batch = torch.stack(patches[i: i+batch_size], dim=0)  # shape: (B, C, window_size, window_size)\n",
    "            batch_pred = pred_func(batch)  # deve retornar shape: (B, nb_classes, window_size, window_size)\n",
    "            preds.append(batch_pred)\n",
    "        preds = torch.cat(preds, dim=0)\n",
    "\n",
    "        # Recria a imagem de predição a partir dos patches processados\n",
    "        pred_img = torch.zeros(nb_classes, H, W, device=input_img.device)\n",
    "        weight_img = torch.zeros(nb_classes, H, W, device=input_img.device)\n",
    "        # Cria a janela 2D para blending (assumindo que _window_2D retorna shape (1,1,window_size,window_size))\n",
    "        window = _window_2D(window_size, power=2).to(input_img.device).squeeze(0).squeeze(0)\n",
    "\n",
    "        idx = 0\n",
    "        for (i, j) in coords:\n",
    "            pred_img[:, i:i+window_size, j:j+window_size] += preds[idx] * window\n",
    "            weight_img[:, i:i+window_size, j:j+window_size] += window\n",
    "            idx += 1\n",
    "\n",
    "        # Normaliza pela soma dos pesos\n",
    "        pred_img = pred_img / weight_img\n",
    "        results.append(pred_img)\n",
    "\n",
    "    # Faz o merge das 8 rotações\n",
    "    final_pred = _rotate_mirror_undo(results)\n",
    "    # Remove o padding\n",
    "    final_pred = _unpad_img(final_pred, window_size, subdivisions)\n",
    "    return final_pred\n",
    "\n",
    "\n",
    "def cheap_tiling_prediction(img, window_size, nb_classes, pred_func):\n",
    "    \"\"\"\n",
    "    Run prediction on non-overlapping patches (with padding to nearest window size multiple)\n",
    "    and merge the results.\n",
    "    \"\"\"\n",
    "    C, H, W = img.shape\n",
    "    full_border_h = H if H % window_size == 0 else H + (window_size - (H % window_size))\n",
    "    full_border_w = W if W % window_size == 0 else W + (window_size - (W % window_size))\n",
    "    prd = torch.zeros((nb_classes, full_border_h, full_border_w), device=img.device)\n",
    "    tmp = torch.zeros((C, full_border_h, full_border_w), device=img.device)\n",
    "    tmp[:, :H, :W] = img\n",
    "    img = tmp\n",
    "    for i in range(0, full_border_h, window_size):\n",
    "        for j in range(0, full_border_w, window_size):\n",
    "            patch = img[:, i:i+window_size, j:j+window_size]\n",
    "            patch_pred = pred_func(patch.unsqueeze(0))  # shape: (1, nb_classes, window_size, window_size)\n",
    "            prd[:, i:i+window_size, j:j+window_size] = patch_pred.squeeze(0)\n",
    "    prd = prd[:, :H, :W]\n",
    "    if PLOT_PROGRESS:\n",
    "        plt.imshow(prd.permute(1, 2, 0).cpu().numpy())\n",
    "        plt.title(\"Cheaply Merged Patches\")\n",
    "        plt.show()\n",
    "    return prd\n",
    "\n",
    "def get_dummy_img(xy_size=128, nb_channels=3):\n",
    "    \"\"\"\n",
    "    Create a random image (tensor of shape (C, H, W)) with spatial variation.\n",
    "    \"\"\"\n",
    "    img = torch.rand(nb_channels, xy_size, xy_size)\n",
    "    img = img + torch.ones((1, xy_size, xy_size))\n",
    "    lin = torch.linspace(0, 1, xy_size)\n",
    "    grid = lin.unsqueeze(0) * lin.unsqueeze(1)  # outer product, shape (xy_size, xy_size)\n",
    "    img = img * grid.unsqueeze(0)\n",
    "    img = img + torch.flip(img, dims=[1, 2])\n",
    "    img = img - img.min()\n",
    "    img = img / img.max() / 2\n",
    "    if PLOT_PROGRESS:\n",
    "        plt.imshow(img.permute(1, 2, 0).cpu().numpy())\n",
    "        plt.title(\"Random image for a test\")\n",
    "        plt.show()\n",
    "    return img\n",
    "\n",
    "def round_predictions(prd, nb_channels_out, thresholds):\n",
    "    \"\"\"\n",
    "    Binarize each channel in the predictions based on the corresponding threshold.\n",
    "    \"\"\"\n",
    "    for i in range(nb_channels_out):\n",
    "        prd[i] = (prd[i] > thresholds[i]).float()\n",
    "    return prd"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "def infer_and_save_full_image_smooth(model, device, image_path, output_path, nb_classes, window_size=256, subdivisions=2):\n",
    "    \"\"\"\n",
    "    Processa uma imagem completa (por exemplo, 6200x4000) usando smooth blending.\n",
    "    A imagem é dividida em patches de tamanho window_size (256×256), cada patch é upscalado para 512×512\n",
    "    para a inferência (pois o modelo espera esse tamanho) e, após a predição, os resultados são\n",
    "    downscale de volta para 256×256 e combinados suavemente para formar a máscara final.\n",
    "\n",
    "    Args:\n",
    "        model: modelo PyTorch para inferência.\n",
    "        device: dispositivo ('cpu' ou 'cuda').\n",
    "        image_path: caminho para a imagem completa.\n",
    "        output_path: caminho para salvar a máscara predita.\n",
    "        nb_classes: número de classes de saída do modelo.\n",
    "        window_size: tamanho do patch original (default: 256).\n",
    "        subdivisions: fator de sobreposição para a função de blending (default: 2).\n",
    "    \"\"\"\n",
    "    # Carrega a imagem completa\n",
    "    image = cv2.imread(image_path)\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Erro ao carregar a imagem: {image_path}\")\n",
    "\n",
    "    # Converte de BGR para RGB\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Pré-processa a imagem (ex.: normalização) conforme seu modelo requer\n",
    "    image = image.astype('float32')\n",
    "    image = preprocess_input(image)  # Função definida externamente\n",
    "\n",
    "    # Converte para tensor no formato (C, H, W)\n",
    "    image_tensor = torch.tensor(image).permute(2, 0, 1).to(device).float()\n",
    "\n",
    "    def pred_func(patches):\n",
    "        #patches_up = F.interpolate(patches, size=(512, 512), mode='bilinear', align_corners=False)\n",
    "        with torch.no_grad(), autocast():\n",
    "            output = model(patches)\n",
    "        output = torch.softmax(output, dim=1)\n",
    "        output_down = F.interpolate(output, size=(256, 256), mode='nearest')\n",
    "        return output_down\n",
    "\n",
    "    # Aplica a função de smooth windowing para processar a imagem inteira.\n",
    "    # A função 'predict_img_with_smooth_windowing' deve estar adaptada para tensores (canais-first)\n",
    "    prediction = predict_img_with_smooth_windowing_batched(\n",
    "        image_tensor, window_size, subdivisions, nb_classes, pred_func\n",
    "    )\n",
    "    # prediction: tensor de shape (nb_classes, H, W) correspondente à imagem completa\n",
    "\n",
    "    # Converte a predição para numpy e aplica argmax para obter a máscara final\n",
    "    prediction_np = prediction.cpu().numpy()\n",
    "    mask = np.argmax(prediction_np, axis=0)  # shape: (H, W)\n",
    "\n",
    "    # Mapeia os valores: ex. classe 0 -> 0, classe 1 -> 127, classe 2 -> 255 (ajuste se necessário)\n",
    "    mask = np.where(mask == 1, 127, np.where(mask == 2, 255, 0)).astype(np.uint8)\n",
    "\n",
    "    # Salva a máscara predita\n",
    "    cv2.imwrite(output_path, mask)\n",
    "    print(f\"Salvo: {output_path}\")"
   ],
   "id": "35954eb9b751c1b5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "preprocess_input = smp.encoders.get_preprocessing_fn('timm-efficientnet-b8', pretrained='imagenet') # Obtemos a função de pré-processamento para o EfficientNet-B8 treinado em ImageNet\n",
    "device = 'cuda' if torch.cuda.is_available else 'cpu' # Escolhe o dispositivo onde vão correr os tensores\n",
    "model = smp.Unet(encoder_name='timm-efficientnet-b8',encoder_weights='imagenet',in_channels=3,classes=3) # Instancia uma Unet com encoder EfficientNet-B8 pré-treinado em ImageNet\n",
    "model.load_state_dict(torch.load(\"uNetB8CombinedCP_BlurPequeno7.pth\")) # Carrega os pesos gravados durante treino a partir do ficheiro .pth\n",
    "model.to(device) # Move o modelo para o dispositivo selecionado (GPU ou CPU)\n",
    "model.eval() # Passa o modelo para modo de inferência"
   ],
   "id": "272c1c6abbdb2227"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "infer_and_save_full_image_smooth(\n",
    "    model,\n",
    "    device,\n",
    "    image_path='inputImage.png',\n",
    "    output_path='outputMask.png',\n",
    "    nb_classes=3\n",
    ")"
   ],
   "id": "359573da520cad15"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
